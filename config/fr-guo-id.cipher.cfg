[OS]
save_dir = saves/fr-guo-id
embed_dir = wrd-emb
embed_file = %(embed_dir)s/guo.vec
clt_src=id
data_dir = data/fr
embed_clt_file=%(data_dir)s/brown.256.20.vec.vec
train_file = %(data_dir)s/train.all.fix
valid_file = %(data_dir)s/dev.lc.lid
test_file = %(data_dir)s/test.conllu.cipher
zero_wrd_emb = True


[Dataset]
min_occur_count = 2
n_bkts = 35
n_valid_bkts = 10

[Layers]
n_recur = 4


[Sizes]
embed_size = 50


[Regularization]
word_l2_reg = 0
l2_reg = 0


[Dropout]
word_keep_prob = .5
tag_keep_prob = 0.8
clt_keep_prob = 1
rel_keep_prob = 1
ff_keep_prob = .8
mlp_keep_prob = .8


[Learning rate]
learning_rate = 2e-3
decay_steps = 2500


[Radam]
chi = 0


[Training]
pretrain_iters = 100
train_iters = 10000
train_batch_size = 5000
test_batch_size = 0
validate_every = 100
print_every = 100
save_every = 10
per_process_gpu_memory_fraction = .65
